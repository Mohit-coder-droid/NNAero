{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73a7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:\\Study\\Intelligence And Learning\\Fluid Mechanics\\Project 2\\Code\\NNAero\")\n",
    "from nnaero.models.vae import *\n",
    "from nnaero.models.training.vae_trainer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064bedf2",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d871113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42496f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize your model\n",
    "import torch.optim.adamw\n",
    "\n",
    "\n",
    "FEAT_SIZE = 257  # As per your code\n",
    "model = VAE(feature_size=FEAT_SIZE, latent_size=32)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Make a good dataset\n",
    "mock_data = torch.randn(1024, FEAT_SIZE)\n",
    "dataset = TensorDataset(mock_data)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Define Configuration\n",
    "# config = VAETrainingConfig(\n",
    "#     lr=5e-4, \n",
    "    # batch_size=64, \n",
    "    # epochs=100,\n",
    "    # kl_annealing=True,\n",
    "    # kl_warmup_epochs=20\n",
    "# )\n",
    "\n",
    "# 3. Create Trainer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "trainer = VAETrainer(model,\n",
    "                     optimizer=optimizer,\n",
    "                    kl_annealing=True,\n",
    "                    warmup_epochs=20,\n",
    "                    checkpoint_dir=\"vae_checkpoints\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a15813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epochs 0: loss: 252.9343032836914\n",
      "For epochs 1: loss: 251.89337635040283\n",
      "For epochs 2: loss: 251.0240821838379\n",
      "For epochs 3: loss: 250.31494235992432\n",
      "For epochs 4: loss: 250.03369045257568\n",
      "For epochs 5: loss: 249.8411464691162\n",
      "For epochs 6: loss: 249.6790361404419\n",
      "For epochs 7: loss: 249.85372734069824\n",
      "For epochs 8: loss: 249.85483074188232\n",
      "For epochs 9: loss: 249.97079944610596\n",
      "For epochs 10: loss: 250.07574653625488\n",
      "For epochs 11: loss: 250.24957370758057\n",
      "For epochs 12: loss: 250.5425443649292\n",
      "For epochs 13: loss: 250.74553298950195\n",
      "For epochs 14: loss: 250.6940402984619\n",
      "For epochs 15: loss: 251.1576919555664\n",
      "For epochs 16: loss: 251.28039455413818\n",
      "For epochs 17: loss: 251.70767211914062\n",
      "For epochs 18: loss: 251.77567100524902\n",
      "For epochs 19: loss: 252.0239381790161\n",
      "For epochs 20: loss: 252.36128902435303\n",
      "For epochs 21: loss: 252.05591297149658\n",
      "For epochs 22: loss: 251.9017219543457\n",
      "For epochs 23: loss: 251.8402853012085\n",
      "For epochs 24: loss: 251.75771522521973\n",
      "For epochs 25: loss: 251.55815601348877\n",
      "For epochs 26: loss: 251.27318859100342\n",
      "For epochs 27: loss: 251.37743949890137\n",
      "For epochs 28: loss: 251.3474407196045\n",
      "For epochs 29: loss: 251.43453693389893\n",
      "For epochs 30: loss: 250.8734359741211\n",
      "For epochs 31: loss: 251.02252101898193\n",
      "For epochs 32: loss: 250.86744117736816\n",
      "For epochs 33: loss: 250.909423828125\n",
      "For epochs 34: loss: 250.62783336639404\n",
      "For epochs 35: loss: 250.27899742126465\n",
      "For epochs 36: loss: 250.3603868484497\n",
      "For epochs 37: loss: 250.2024440765381\n",
      "For epochs 38: loss: 250.11958694458008\n",
      "For epochs 39: loss: 250.1441593170166\n",
      "For epochs 40: loss: 249.7658452987671\n",
      "For epochs 41: loss: 249.86034774780273\n",
      "For epochs 42: loss: 249.64663982391357\n",
      "For epochs 43: loss: 249.56833457946777\n",
      "For epochs 44: loss: 249.38289165496826\n",
      "For epochs 45: loss: 249.25415134429932\n",
      "For epochs 46: loss: 249.1013355255127\n",
      "For epochs 47: loss: 249.24941158294678\n",
      "For epochs 48: loss: 248.6369924545288\n",
      "For epochs 49: loss: 248.45701026916504\n",
      "For epochs 50: loss: 248.58824157714844\n",
      "For epochs 51: loss: 248.52598571777344\n",
      "For epochs 52: loss: 248.45883560180664\n",
      "For epochs 53: loss: 248.28930282592773\n",
      "For epochs 54: loss: 247.97326278686523\n",
      "For epochs 55: loss: 247.98580360412598\n",
      "For epochs 56: loss: 248.02458477020264\n",
      "For epochs 57: loss: 247.72129154205322\n",
      "For epochs 58: loss: 247.59061431884766\n",
      "For epochs 59: loss: 247.36694431304932\n",
      "For epochs 60: loss: 247.4098539352417\n",
      "For epochs 61: loss: 246.98421955108643\n",
      "For epochs 62: loss: 247.1191987991333\n",
      "For epochs 63: loss: 247.0706377029419\n",
      "For epochs 64: loss: 246.74220752716064\n",
      "For epochs 65: loss: 246.5106725692749\n",
      "For epochs 66: loss: 246.51545429229736\n",
      "For epochs 67: loss: 246.58272647857666\n",
      "For epochs 68: loss: 246.28140258789062\n",
      "For epochs 69: loss: 246.13898849487305\n",
      "For epochs 70: loss: 246.3978509902954\n",
      "For epochs 71: loss: 245.82750129699707\n",
      "For epochs 72: loss: 246.08619785308838\n",
      "For epochs 73: loss: 245.62612056732178\n",
      "For epochs 74: loss: 245.44711875915527\n",
      "For epochs 75: loss: 245.51216983795166\n",
      "For epochs 76: loss: 245.46585083007812\n",
      "For epochs 77: loss: 245.29779720306396\n",
      "For epochs 78: loss: 245.29036712646484\n",
      "For epochs 79: loss: 245.13180541992188\n",
      "For epochs 80: loss: 244.84007740020752\n",
      "For epochs 81: loss: 244.6416826248169\n",
      "For epochs 82: loss: 244.3903169631958\n",
      "For epochs 83: loss: 244.41652584075928\n",
      "For epochs 84: loss: 244.28167533874512\n",
      "For epochs 85: loss: 244.65827083587646\n",
      "For epochs 86: loss: 244.12513160705566\n",
      "For epochs 87: loss: 244.05157852172852\n",
      "For epochs 88: loss: 243.78691005706787\n",
      "For epochs 89: loss: 243.77254009246826\n",
      "For epochs 90: loss: 243.72052478790283\n",
      "For epochs 91: loss: 243.31817817687988\n",
      "For epochs 92: loss: 243.2688913345337\n",
      "For epochs 93: loss: 243.0940399169922\n",
      "For epochs 94: loss: 243.14108848571777\n",
      "For epochs 95: loss: 242.80380058288574\n",
      "For epochs 96: loss: 242.48186016082764\n",
      "For epochs 97: loss: 242.7887201309204\n",
      "For epochs 98: loss: 242.57838439941406\n",
      "For epochs 99: loss: 242.45991611480713\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "\n",
    "history = []\n",
    "for i in range(EPOCHS):\n",
    "    history.append(trainer.train_epoch(train_loader, i))\n",
    "    print(f\"For epochs {i}: loss: {history[i]['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc385d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ccaf741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258.3489294052124"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[0][\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0370ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
